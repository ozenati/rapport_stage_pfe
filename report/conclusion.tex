Solving large systems of linear equations is one of the most important operations in matrix computation and represents a time-consuming step, arising in many scientific and engineering applications. The LU decomposition algorithm is used in most state of the art libraries such as in Matlab, Lapack and HPL libraries. Its expression is much more complex because part of the operations to be performed have to be scheduled dynamically based on numerical criteria. Despite this difficulty, we managed to implement a task flow LU decomposition with PTG and obtained promising performances.

We try now to optimize the \dague runtime system to better manage the small communications messages, in order to take full advantage of all cores of nodes. 
Thanks to this representation of the algorithm, we hope to create an algorithm that will fully exploit heterogeneous architectures by offloading GEMM to accelerators as GPUs or Intel MIC on distributed architectures. Nowadays, GPU implementations of the LU partial pivoting are either relying on the ScaLAPACK sequential execution of the algorithm or HPL implementation and basically offload the GEMM on the GPU, or are able to fully exploit a single heterogeneous node by using block-column distribution. The first solution prevents enabling dynamic scheduling and automatic look-ahead specific to tile algorithm, while the second solution would be a disaster in the load balance on distributed architectures where a 2D block-cyclic distribution is required to decrease the volume of communication and average out the load over the multiple nodes. Thus, our implementation of LU decomposition over \dague will be the right solution to keep an automatic scheduling and good load balance on heterogeneous architectures to achieve better performances.
%We will be able to have one of the most efficient LU decomposition implementation. Beside its use for resolving system of linear equations, it will be possible to create a new benchmark to analyse computers performances.

In parallel, we implemented another task flow LU decomposition on StarPU. In fact, StarPU runtime allow to implement dynamic algorithm  thanks to its task insertion system. Moreover, it allows to make \emph{reduce} operation which enable to select the best pivot without using tree implementation. For now, the results obtained are not efficient. We are still investigating to understand the lack of performance. Thereafter, we will be able to compare results to PTG in general and \dague particularly.