LU decomposition with partial pivoting is a dynamic algorithm with its data dependencies in the swapping operation for the update. Despite this difficulty, we managed to implement a task flow LU decomposition with PTG and obtained promising performances.

We try now to optimize the \dague runtime system to better manage the small communications messages, in order to take full advantage of all cores of nodes. 
Thanks to this representation of the algorithm, we hope to create an algorithm that will fully exploit heterogeneous architectures by offloading GEMM to accelerators as GPUs or Intel MIC on distributed architectures. Nowadays, GPU implementations of the LU partial pivoting are either relying on the ScaLAPACK sequential execution of the algorithm or HPL implementation and basically offload the GEMM on the GPU, or are able to fully exploit a single heterogeneous node by using block-column distribution. The first solution prevents enabling dynamic scheduling and automatic look-ahead specific to tile algorithm, while the second solution would be a disaster in the load balance on distributed architectures where a 2D block-cyclic distribution is required to decrease the volume of communication and average out the load over the multiple nodes. Thus, our implementation of LU decomposition over \dague will be the right solution to keep an automatic scheduling and good load balance on heterogeneous architectures to achieve better performances.
%We will be able to have one of the most efficient LU decomposition implementation. Beside its use for resolving system of linear equations, it will be possible to create a new benchmark to analyse computers performances.

In parallel, we implemented another task flow LU decomposition on StarPU. In fact, StarPU runtime allow to implement dynamic algorithm  thanks to its task insertion system. Moreover, it allows to make \emph{reduce} operation which enable to select the best pivot without using tree implementation. We will be able to compare results to PTG in general and \dague particularly.